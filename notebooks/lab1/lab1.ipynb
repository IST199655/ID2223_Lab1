{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from functions import util\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Backfill feature pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a backfill feature pipeline that downloads historical weather data (ideally >1\n",
    "year of data), loads a csv file with historical air quality data (downloaded from\n",
    "https://aqicn.org) and registers them as 2 Feature Groups with Hopsworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import air quality data on 5 years at Stockholm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pm10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  pm25  pm10\n",
       "0 2024-11-01     8     3\n",
       "1 2024-11-02     5     3\n",
       "2 2024-11-03     6     6\n",
       "3 2024-11-04     7     4\n",
       "4 2024-11-05    11     6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality_df = pd.read_csv(\"../../data/stockholm-hornsgatan 108 gata-air-quality.csv\")\n",
    "\n",
    "air_quality_df['date'] = pd.to_datetime(air_quality_df['date'], format='%Y/%m/%d')\n",
    "\n",
    "# Handle non-numeric values in 'pm25' and 'pm10', replace them with NaN\n",
    "air_quality_df['pm25'] = pd.to_numeric(air_quality_df['pm25'], errors='coerce')\n",
    "air_quality_df['pm10'] = pd.to_numeric(air_quality_df['pm10'], errors='coerce')\n",
    "\n",
    "# Fill NaN values with 0 (or use mean or another method depending on your choice)\n",
    "air_quality_df['pm25'].fillna(0, inplace=True)\n",
    "air_quality_df['pm10'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert 'pm25' and 'pm10' columns to integers\n",
    "air_quality_df['pm25'] = air_quality_df['pm25'].astype(int)\n",
    "air_quality_df['pm10'] = air_quality_df['pm10'].astype(int)\n",
    "\n",
    "\n",
    "air_quality_df = air_quality_df.drop(columns=['no2'])\n",
    "\n",
    "\n",
    "air_quality_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import weather data on one year at Stockholm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 59.29701232910156°N 18.163265228271484°E\n",
      "Elevation 24.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>14.615000</td>\n",
       "      <td>10.214999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>18.391737</td>\n",
       "      <td>209.271942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>13.565000</td>\n",
       "      <td>7.415000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>22.206486</td>\n",
       "      <td>248.656326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>11.014999</td>\n",
       "      <td>5.965000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>16.595179</td>\n",
       "      <td>306.521240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-06</td>\n",
       "      <td>11.165000</td>\n",
       "      <td>6.215000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>23.871555</td>\n",
       "      <td>320.408325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-07</td>\n",
       "      <td>8.815000</td>\n",
       "      <td>4.215000</td>\n",
       "      <td>6.300001</td>\n",
       "      <td>14.332341</td>\n",
       "      <td>343.018829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>8.714999</td>\n",
       "      <td>3.415000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.864674</td>\n",
       "      <td>257.650360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>7.365000</td>\n",
       "      <td>4.665000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.428097</td>\n",
       "      <td>257.365479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>2024-11-10</td>\n",
       "      <td>7.065000</td>\n",
       "      <td>4.415000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>9.292255</td>\n",
       "      <td>145.380463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>5.665000</td>\n",
       "      <td>3.615000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>9.676569</td>\n",
       "      <td>234.773972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>2024-11-12</td>\n",
       "      <td>4.965000</td>\n",
       "      <td>1.315000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.990322</td>\n",
       "      <td>288.903290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2598 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  temperature_2m_max  temperature_2m_min  precipitation_sum  \\\n",
       "0    2017-10-03           14.615000           10.214999           0.500000   \n",
       "1    2017-10-04           13.565000            7.415000           2.900000   \n",
       "2    2017-10-05           11.014999            5.965000           2.600000   \n",
       "3    2017-10-06           11.165000            6.215000           0.500000   \n",
       "4    2017-10-07            8.815000            4.215000           6.300001   \n",
       "...         ...                 ...                 ...                ...   \n",
       "2593 2024-11-08            8.714999            3.415000           0.000000   \n",
       "2594 2024-11-09            7.365000            4.665000           0.000000   \n",
       "2595 2024-11-10            7.065000            4.415000           0.100000   \n",
       "2596 2024-11-11            5.665000            3.615000           1.100000   \n",
       "2597 2024-11-12            4.965000            1.315000           0.000000   \n",
       "\n",
       "      wind_speed_10m_max  wind_direction_10m_dominant  \n",
       "0              18.391737                   209.271942  \n",
       "1              22.206486                   248.656326  \n",
       "2              16.595179                   306.521240  \n",
       "3              23.871555                   320.408325  \n",
       "4              14.332341                   343.018829  \n",
       "...                  ...                          ...  \n",
       "2593           13.864674                   257.650360  \n",
       "2594           14.428097                   257.365479  \n",
       "2595            9.292255                   145.380463  \n",
       "2596            9.676569                   234.773972  \n",
       "2597           10.990322                   288.903290  \n",
       "\n",
       "[2598 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Coordinates of Stockholm and date range for historical data\n",
    "latitude = 59.3293\n",
    "longitude = 18.0686\n",
    "today = datetime.today().date()\n",
    "start_date = today - timedelta(days=365)\n",
    "end_date = today - timedelta(days=2)\n",
    "\n",
    "country=\"sweden\"\n",
    "city = \"stockholm\"\n",
    "street = \"stockholm-hornsgatan-108\"\n",
    "aqicn_url=\"https://api.waqi.info/feed/@10009\"\n",
    "\n",
    "earliest_aq_date = pd.Series.min(air_quality_df['date'])\n",
    "earliest_aq_date = earliest_aq_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Calculate daily average temperature\n",
    "df_weather = util.get_historical_weather(city, earliest_aq_date, str(today), latitude, longitude)\n",
    "\n",
    "# Print the result\n",
    "df_weather = df_weather.drop(columns='city')\n",
    "\n",
    "df_weather\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Connection to hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "with open('../../data/hopsworks-api-key.txt', 'r') as file:\n",
    "    os.environ[\"HOPSWORKS_API_KEY\"] = file.read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1170583\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "project = hopsworks.login(project=\"ID2223LAB1KTH\")\n",
    "fs = project.get_feature_store()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1170583/featurestores/1161286/featuregroups). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270089,\"usrMsg\":\"project: ID2223LAB1KTH, featurestoreId: 1161286\",\"errorMsg\":\"The feature group you are trying to create does already exist.\"}', error code: 270089, error msg: The feature group you are trying to create does already exist., user msg: project: ID2223LAB1KTH, featurestoreId: 1161286",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a weather data feature group\u001b[39;00m\n\u001b[1;32m      2\u001b[0m weather_fg \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mcreate_feature_group(\n\u001b[1;32m      3\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstockholm_weather\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     event_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mweather_fg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_weather\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeather feature group created and data inserted successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/feature_group.py:2528\u001b[0m, in \u001b[0;36mFeatureGroup.insert\u001b[0;34m(self, features, overwrite, operation, storage, write_options, validation_options, save_code, wait)\u001b[0m\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m write_options:\n\u001b[1;32m   2526\u001b[0m     write_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m wait\n\u001b[0;32m-> 2528\u001b[0m job, ge_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_group_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2531\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2532\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_report\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalidation_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_code \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   2538\u001b[0m     ge_report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ge_report\u001b[38;5;241m.\u001b[39mingestion_result \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINGESTED\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2539\u001b[0m ):\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_engine\u001b[38;5;241m.\u001b[39msave_code(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/core/feature_group_engine.py:91\u001b[0m, in \u001b[0;36mFeatureGroupEngine.insert\u001b[0;34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m dataframe_features \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mparse_schema_feature_group(\n\u001b[1;32m     86\u001b[0m     feature_dataframe, feature_group\u001b[38;5;241m.\u001b[39mtime_travel_format\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m feature_group\u001b[38;5;241m.\u001b[39m_id:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# only save metadata if feature group does not exist\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_feature_group_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_options\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# else, just verify that feature group schema matches user-provided dataframe\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_schema_compatibility(\n\u001b[1;32m     97\u001b[0m         feature_group\u001b[38;5;241m.\u001b[39mfeatures, dataframe_features\n\u001b[1;32m     98\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/core/feature_group_engine.py:371\u001b[0m, in \u001b[0;36mFeatureGroupEngine.save_feature_group_metadata\u001b[0;34m(self, feature_group, dataframe_features, write_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m     _write_options \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    359\u001b[0m         [\n\u001b[1;32m    360\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: k, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: v}\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[1;32m    367\u001b[0m     feature_group\u001b[38;5;241m.\u001b[39m_deltastreamer_jobconf \u001b[38;5;241m=\u001b[39m DeltaStreamerJobConf(\n\u001b[1;32m    368\u001b[0m         _write_options, _spark_options\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_group_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Group created successfully, explore it at \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;241m+\u001b[39m util\u001b[38;5;241m.\u001b[39mget_feature_group_url(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m     )\n\u001b[1;32m    378\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/core/feature_group_api.py:55\u001b[0m, in \u001b[0;36mFeatureGroupApi.save\u001b[0;34m(self, feature_group_instance)\u001b[0m\n\u001b[1;32m     46\u001b[0m path_params \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m     _client\u001b[38;5;241m.\u001b[39m_project_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeaturegroups\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     52\u001b[0m ]\n\u001b[1;32m     53\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     54\u001b[0m feature_group_object \u001b[38;5;241m=\u001b[39m feature_group_instance\u001b[38;5;241m.\u001b[39mupdate_from_response_json(\n\u001b[0;32m---> 55\u001b[0m     \u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_group_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     62\u001b[0m feature_group_object\u001b[38;5;241m.\u001b[39mfeature_store \u001b[38;5;241m=\u001b[39m feature_group_instance\u001b[38;5;241m.\u001b[39mfeature_store\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_group_object\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/client/base.py:176\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    171\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_token_expired(\n\u001b[1;32m    172\u001b[0m         request, stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTOKEN_EXPIRED_RETRY_INTERVAL, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1170583/featurestores/1161286/featuregroups). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270089,\"usrMsg\":\"project: ID2223LAB1KTH, featurestoreId: 1161286\",\"errorMsg\":\"The feature group you are trying to create does already exist.\"}', error code: 270089, error msg: The feature group you are trying to create does already exist., user msg: project: ID2223LAB1KTH, featurestoreId: 1161286"
     ]
    }
   ],
   "source": [
    "# Create a weather data feature group\n",
    "weather_fg = fs.create_feature_group(\n",
    "    name=\"stockholm_weather\",\n",
    "    version=1,\n",
    "    description=\"Weather data for Stockholm including temperature, humidity, wind speed, and wind direction\",\n",
    "    primary_key=[\"date\"],  \n",
    "    event_time=\"date\" \n",
    ")\n",
    "\n",
    "\n",
    "weather_fg.insert(df_weather)\n",
    "\n",
    "print(\"Weather feature group created and data inserted successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1170583/fs/1161286/fg/1347959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3ed454784541db9753bdc09902e3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/2557 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: stockholm_air_quality_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1170583/jobs/named/stockholm_air_quality_1_offline_fg_materialization/executions\n",
      "Air quality feature group created and data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "air_quality_fg = fs.create_feature_group(\n",
    "    name=\"stockholm_air_quality\",\n",
    "    version=1,\n",
    "    description=\"Air quality data for Stockholm with PM2.5 concentrations\",\n",
    "    primary_key=[\"date\"],  # 'time' column as the primary key\n",
    "    event_time=\"date\"      # Specify 'time' as the event time\n",
    ")\n",
    "\n",
    "\n",
    "air_quality_fg.insert(air_quality_df)\n",
    "\n",
    "print(\"Air quality feature group created and data inserted successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schedule a daily feature pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In .github/workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Write a training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.96s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.04s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pm10</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-23 00:00:00+00:00</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.435000</td>\n",
       "      <td>-5.9850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.079027</td>\n",
       "      <td>241.394394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-27 00:00:00+00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>17.715000</td>\n",
       "      <td>2.7650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.245697</td>\n",
       "      <td>193.671310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-24 00:00:00+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>12.815000</td>\n",
       "      <td>6.2150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.113451</td>\n",
       "      <td>191.237717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-14 00:00:00+00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>19.765001</td>\n",
       "      <td>11.4150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.336637</td>\n",
       "      <td>180.159409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-17 00:00:00+00:00</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>8.264999</td>\n",
       "      <td>2.4150</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22.267679</td>\n",
       "      <td>199.835754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>2024-11-15 00:00:00+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8.567500</td>\n",
       "      <td>5.0675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>253.295898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>2024-11-17 00:00:00+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.798225</td>\n",
       "      <td>241.314667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>2024-11-19 00:00:00+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>-2.1500</td>\n",
       "      <td>1.4</td>\n",
       "      <td>23.444265</td>\n",
       "      <td>62.416252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>2024-11-18 00:00:00+00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.806337</td>\n",
       "      <td>268.170380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>2024-11-16 00:00:00+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>11.267500</td>\n",
       "      <td>4.7000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32.760002</td>\n",
       "      <td>246.982422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2562 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  pm25  pm10  temperature_2m_max  \\\n",
       "0    2023-01-23 00:00:00+00:00    42     7           -2.435000   \n",
       "1    2023-05-27 00:00:00+00:00    16    23           17.715000   \n",
       "2    2019-09-24 00:00:00+00:00    10     9           12.815000   \n",
       "3    2018-06-14 00:00:00+00:00    20    23           19.765001   \n",
       "4    2019-11-17 00:00:00+00:00    40    19            8.264999   \n",
       "...                        ...   ...   ...                 ...   \n",
       "2557 2024-11-15 00:00:00+00:00    10     8            8.567500   \n",
       "2558 2024-11-17 00:00:00+00:00     4     4            6.100000   \n",
       "2559 2024-11-19 00:00:00+00:00     5     5            3.700000   \n",
       "2560 2024-11-18 00:00:00+00:00     8     7            3.100000   \n",
       "2561 2024-11-16 00:00:00+00:00     6     4           11.267500   \n",
       "\n",
       "      temperature_2m_min  precipitation_sum  wind_speed_10m_max  \\\n",
       "0                -5.9850                0.0           18.079027   \n",
       "1                 2.7650                0.0           19.245697   \n",
       "2                 6.2150                0.0           11.113451   \n",
       "3                11.4150                0.0           24.336637   \n",
       "4                 2.4150                0.2           22.267679   \n",
       "...                  ...                ...                 ...   \n",
       "2557              5.0675                0.0           21.959999   \n",
       "2558              3.0000                0.0           24.798225   \n",
       "2559             -2.1500                1.4           23.444265   \n",
       "2560             -1.0000                0.0           18.806337   \n",
       "2561              4.7000                0.1           32.760002   \n",
       "\n",
       "      wind_direction_10m_dominant  \n",
       "0                      241.394394  \n",
       "1                      193.671310  \n",
       "2                      191.237717  \n",
       "3                      180.159409  \n",
       "4                      199.835754  \n",
       "...                           ...  \n",
       "2557                   253.295898  \n",
       "2558                   241.314667  \n",
       "2559                    62.416252  \n",
       "2560                   268.170380  \n",
       "2561                   246.982422  \n",
       "\n",
       "[2562 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Feature Groups for air quality and weather data\n",
    "air_quality_fg = fs.get_feature_group(name=\"stockholm_air_quality\", version=1)\n",
    "weather_fg = fs.get_feature_group(name=\"stockholm_weather\", version=1)\n",
    "\n",
    "# Read the data from both feature groups\n",
    "air_quality_df = air_quality_fg.read()\n",
    "weather_df = weather_fg.read()\n",
    "\n",
    "# Merge the two feature groups on the 'time' column\n",
    "merged_df = air_quality_df.merge(weather_df, on=\"date\", how=\"inner\")\n",
    "\n",
    "# Select features and target for training\n",
    "features = merged_df[['temperature_2m_max','temperature_2m_min','precipitation_sum','wind_speed_10m_max','wind_direction_10m_dominant']]\n",
    "target = merged_df['pm25']\n",
    "\n",
    "merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.26s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>temperature_2m_max</th>\n",
       "      <th>temperature_2m_min</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-01 00:00:00+00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>2.215</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20.730501</td>\n",
       "      <td>347.482971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02 00:00:00+00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>3.765</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.546833</td>\n",
       "      <td>226.255768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-10 00:00:00+00:00</td>\n",
       "      <td>38</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-6.435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.239453</td>\n",
       "      <td>89.506119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-05 00:00:00+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>-3.635</td>\n",
       "      <td>-9.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.684735</td>\n",
       "      <td>325.287720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-03 00:00:00+00:00</td>\n",
       "      <td>24</td>\n",
       "      <td>-3.735</td>\n",
       "      <td>-9.185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.495713</td>\n",
       "      <td>2.309032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-03-20 00:00:00+00:00</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.835</td>\n",
       "      <td>-14.885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.626984</td>\n",
       "      <td>342.335846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-03-26 00:00:00+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-7.335</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17.709658</td>\n",
       "      <td>26.193710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-04-23 00:00:00+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>9.365</td>\n",
       "      <td>3.465</td>\n",
       "      <td>2.9</td>\n",
       "      <td>21.434364</td>\n",
       "      <td>167.404770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-05-09 00:00:00+00:00</td>\n",
       "      <td>29</td>\n",
       "      <td>17.615</td>\n",
       "      <td>8.315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.799459</td>\n",
       "      <td>133.503128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-06-06 00:00:00+00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>16.365</td>\n",
       "      <td>4.465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.811815</td>\n",
       "      <td>298.059235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  pm25  temperature_2m_max  temperature_2m_min  \\\n",
       "0 2017-12-01 00:00:00+00:00    12               2.215              -0.085   \n",
       "1 2018-01-02 00:00:00+00:00     9               3.765               0.865   \n",
       "2 2018-01-10 00:00:00+00:00    38               0.115              -6.435   \n",
       "3 2018-02-05 00:00:00+00:00    21              -3.635              -9.585   \n",
       "4 2018-03-03 00:00:00+00:00    24              -3.735              -9.185   \n",
       "5 2018-03-20 00:00:00+00:00    32              -0.835             -14.885   \n",
       "6 2018-03-26 00:00:00+00:00    28              -0.335              -7.335   \n",
       "7 2018-04-23 00:00:00+00:00    17               9.365               3.465   \n",
       "8 2018-05-09 00:00:00+00:00    29              17.615               8.315   \n",
       "9 2018-06-06 00:00:00+00:00    13              16.365               4.465   \n",
       "\n",
       "   precipitation_sum  wind_speed_10m_max  wind_direction_10m_dominant  \n",
       "0                0.4           20.730501                   347.482971  \n",
       "1                0.3           15.546833                   226.255768  \n",
       "2                0.0           10.239453                    89.506119  \n",
       "3                0.0           13.684735                   325.287720  \n",
       "4                0.0           10.495713                     2.309032  \n",
       "5                0.0           21.626984                   342.335846  \n",
       "6                0.5           17.709658                    26.193710  \n",
       "7                2.9           21.434364                   167.404770  \n",
       "8                0.0           14.799459                   133.503128  \n",
       "9                0.0           17.811815                   298.059235  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = air_quality_fg.select(['date','pm25']).join(weather_fg.select_all(), on = ['date'])\n",
    "selected_features.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-01-15 00:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order data by dates to find good date to split\n",
    "dates_ordered = merged_df.sort_values(by = 'date').date\n",
    "\n",
    "# define train/test split\n",
    "train_per = 0.7\n",
    "train_split = int(dates_ordered.shape[0]*train_per)\n",
    "\n",
    "# find correct date to split\n",
    "start_test_date = dates_ordered[train_split+1]\n",
    "start_test_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1170583/featurestores/1161286/featureview/air%20quality%20fv/version/1). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":120004,\"usrMsg\":\"HTTP 404 Not Found\",\"errorMsg\":\"Web application exception occurred\"}', error code: 120004, error msg: Web application exception occurred, user msg: HTTP 404 Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_view \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_feature_view\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mair quality fv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweather features with air quality as the target\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpm25\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mselected_features\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/usage.py:212\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    211\u001b[0m     exception \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/usage.py:208\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# Call the original method\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/feature_store.py:1622\u001b[0m, in \u001b[0;36mFeatureStore.get_or_create_feature_view\u001b[0;34m(self, name, query, version, description, labels, inference_helper_columns, training_helper_columns, transformation_functions)\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_feature_view(\n\u001b[1;32m   1612\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   1613\u001b[0m         query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         transformation_functions\u001b[38;5;241m=\u001b[39mtransformation_functions,\n\u001b[1;32m   1620\u001b[0m     )\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/feature_store.py:1605\u001b[0m, in \u001b[0;36mFeatureStore.get_or_create_feature_view\u001b[0;34m(self, name, query, version, description, labels, inference_helper_columns, training_helper_columns, transformation_functions)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get feature view metadata object or create a new one if it doesn't exist. This method doesn't update\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;124;03mexisting feature view metadata object.\u001b[39;00m\n\u001b[1;32m   1554\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;124;03m    `FeatureView`: The feature view metadata object.\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_view_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1608\u001b[0m         e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m270181\u001b[39m\n\u001b[1;32m   1609\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m\n\u001b[1;32m   1610\u001b[0m     ):\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/core/feature_view_engine.py:127\u001b[0m, in \u001b[0;36mFeatureViewEngine.get\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version:\n\u001b[0;32m--> 127\u001b[0m         fv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_view_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_by_name_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattach_transformation_function(fv)\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/core/feature_view_api.py:113\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get back the feature view because the query defined is no longer valid.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or `FeatureView.clean`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/core/feature_view_api.py:101\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m     98\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path \u001b[38;5;241m+\u001b[39m [name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_VERSION, version]\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_view\u001b[38;5;241m.\u001b[39mFeatureView\u001b[38;5;241m.\u001b[39mfrom_response_json(\n\u001b[0;32m--> 101\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     )\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m270009\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Scalable ML and DeepL/ID2223_Lab1/lab1_env/lib/python3.12/site-packages/hsfs/client/base.py:176\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    171\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_token_expired(\n\u001b[1;32m    172\u001b[0m         request, stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTOKEN_EXPIRED_RETRY_INTERVAL, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1170583/featurestores/1161286/featureview/air%20quality%20fv/version/1). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":120004,\"usrMsg\":\"HTTP 404 Not Found\",\"errorMsg\":\"Web application exception occurred\"}', error code: 120004, error msg: Web application exception occurred, user msg: HTTP 404 Not Found"
     ]
    }
   ],
   "source": [
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name = \"air quality fv\",\n",
    "    description = \"weather features with air quality as the target\",\n",
    "    version = 1,\n",
    "    labels = ['pm25'],\n",
    "    query = selected_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
